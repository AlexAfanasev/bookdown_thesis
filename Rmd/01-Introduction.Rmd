---
output: pdf_document
editor_options: 
  chunk_output_type: console
---

\mainmatter

# Introduction {#intro}

**Content:**

- Describe Goals of thesis and relation to previous work (Determinants of the price dividend ratio)
    
    - Extend estimation of latent state (mean price dividend ratio) by including possible economic determinants
    
- Describe the purpose of the MCMC Extension (benefits and possible disadvantages)

    - Advantage because of short time series (prior information from previous study)???
    
    - verification with simulation study (linear and nonlinear case)
    
```{r, introduction_source, eval=FALSE}
source(here::here("R", "pd_pomp.R"), local = knitr::knit_global())
```

```{r, read_data, include=FALSE, echo=FALSE, eval=FALSE}
# read in data
dataset <- readODS::read_ods(here::here("data", "final_dataset.ods"))
relevant_columns <- c(
    "Date",
    "Real Consumption (per Capita)",
    "Consumption (per Capita)",
    "USPOPTO",
    "USPOP24Y",
    "USPOP29Y",
    "USPOP44Y",
    "USPOP49Y",
    "S&P",
    "Dividend",
    "Earnings",
    "CPI",
    "rf",
    "fund_rate",
    "real_m1"
)
# filter relevant columns
dataset <- dataset[, relevant_columns]

# rename columns
renamed_columns <- c(
    "date",
    "real_consumption",
    "consumption",
    "us_pop_total",
    "us_pop_20_24",
    "us_pop_25_29",
    "us_pop_40_44",
    "us_pop_45_49",
    "price",
    "dividend",
    "earnings",
    "cpi",
    "rf",
    "fund_rate",
    "real_m1"
)
colnames(dataset) <- renamed_columns
row.names(dataset) <- dataset$date
dataset <- dataset[, colnames(dataset)[2:length(colnames(dataset))]]

# transform to xts object
dataset <- xts::xts(
    dataset, order.by = as.Date(row.names(dataset), "%Y-%m-%d")
)
dataset <- dataset["1949-12-31/2019-12-31"]

# linear interpolation for population data
pop_columns <- c(
    "us_pop_total",
    "us_pop_20_24",
    "us_pop_25_29",
    "us_pop_40_44",
    "us_pop_45_49"
)
dataset[
    -dataset[xts:::endof(dataset, "years"), which.i = TRUE],
    pop_columns
] <- NA
storage.mode(dataset) <- "numeric"

dataset[, pop_columns] <- zoo::na.approx(dataset[, pop_columns])
dataset <- dataset[complete.cases(dataset), ]
# dataset <- dataset[xts:::endof(dataset, "years")]

head(dataset)
```

```{r, consumption_volatility, include=FALSE, eval=TRUE, eval=FALSE}
con <- dataset$real_consumption
quar_c_growth <- diff(con) / lag(con, k = 1)
quar_c_growth <- quar_c_growth[!is.na(quar_c_growth)]
quar_c_growth <- quar_c_growth - mean(quar_c_growth)
con_vol <- log(zoo::rollapply(abs(quar_c_growth), width = 20, FUN = sum, 
                              align = "right"))
```

```{r, middle_aged_young_ratio, include=FALSE, eval=FALSE}
middle_aged <- dataset$us_pop_40_44 + dataset$us_pop_45_49
young <- dataset$us_pop_20_24 + dataset$us_pop_25_29
middle_aged_young_ratio <- middle_aged / young
```

## Model

**Measurement:**

$$\eta_{t} = \frac{k_{t}}{1-\rho_{t}}+\sum_{i\;=\;1}^{\infty}\rho^{i-1}_{t}\tilde{E}[\Delta d^{e}_{t+i}-r_{t+i}^{e}] + \epsilon_{t}$$

$$\epsilon_{t} \sim N(0, \sigma_{\epsilon}^2)$$

$$\rho_{t} = \frac{1}{1+exp(-\tilde{\eta_{t}})}$$

$$k_{t} = -ln(\rho_{t})-(1-\rho_{t})ln\bigg(\frac{1}{\rho_{t}} - 1\bigg)$$

**State:**

$$\tilde{\eta}_{t} = \tilde{\eta}_{t-1} + u_{t}$$

**Model with covariates:**

$$\tilde{\eta}_{t} = \beta_{0} + \beta_{1}\tilde{\eta}_{t-1} + \beta_{2}cr_{t-1} + \beta_{3}my_{t-1} + \beta_{4}fr_{t-1} + \beta_{5}ms_{t-1} + u_{t}$$

$$u_{t} \sim N(0, \sigma_{u}^2)$$

## Estimation

**Data:**

- *lpd*: log price dividend ratio
- *d_e*: excess dividends
- *r_e*: excess returns
- *infl*: inflation
- *cr*: consumption risk
- *my*: middle aged to young ratio
- *fr*: effective federal funds rate
- *ms*: log real money supply m1

```{r, data_for_estimation, echo=FALSE, eval=FALSE}
sub_dataset <- dataset

r_e <- (
  log((sub_dataset$price + sub_dataset$dividend) / 
        stats::lag(sub_dataset$price, k = 1))
  - log(1 + (sub_dataset$rf / 100))
)
d_e <- (
  log(sub_dataset$dividend / stats::lag(sub_dataset$dividend, k = 1))
  - log(1 + (sub_dataset$rf / 100))
)
con_vol <- con_vol
my <- middle_aged_young_ratio
fr <- log(1 + (sub_dataset$fund_rate/100))
ms <- log(sub_dataset$real_m1)
inflation <- (diff(sub_dataset$cpi) / stats::lag(sub_dataset$cpi, k = 1))
lpd <- log((sub_dataset$price / sub_dataset$dividend))

var_data <- cbind(lpd, d_e, r_e, inflation, con_vol, my, fr, ms)
var_data <- var_data[complete.cases(var_data),]

## dynamic var
starting_point <- 31
params <- matrix(nrow = nrow(var_data) - starting_point + 1, ncol = 20)
for (i in starting_point:nrow(var_data)) {
    residuals_model <- vector("numeric", length = 11)
    for (w in 20:30) {
        var_model <- vars::VAR(var_data[(i - w):i, 1:4], p = 1,
                               type = "const")
        residuals_j <- tail(residuals(var_model), 10)[, c(2, 3)]
        residuals_model[w - 19] <- sqrt(
            mean((residuals_j[, 1] - residuals_j[, 2])^2)
        )
    }
    best_model <- which.min(residuals_model)
    model <- vars::VAR(var_data[(i - best_model - 19):i, 1:4], type = "const")
    params[i - starting_point + 1, ] <- as.vector(t(vars::Bcoef(model)))
}

var_data <- cbind(var_data[starting_point:nrow(var_data), ], params)

## static var
# starting_point <- 21
# params <- matrix(nrow = nrow(var_data) - starting_point + 1, ncol = 20)
# for (i in starting_point:nrow(var_data)) {
#   model <- vars::VAR(var_data[(i - starting_point + 1):i, 1:4], type = "const")
#   params[i - starting_point + 1, ] <- as.vector(t(vars::Bcoef(model)))
# }
# var_data <- cbind(var_data[starting_point:nrow(var_data), ], params)

## complete var
# starting_point <- 21
# params <- matrix(nrow = nrow(var_data) - starting_point + 1, ncol = 20)
# for (i in starting_point:nrow(var_data)) {
#   model <- vars::VAR(var_data[1:i, 1:4], type = "const")
#   params[i - starting_point + 1, ] <- as.vector(t(vars::Bcoef(model)))
# }
# var_data <- cbind(var_data[starting_point:nrow(var_data), ], params)

y <- var_data[complete.cases(var_data),]
y <- cbind(1:nrow(y), y)
colnames(y) <- c("time", "lpd", "d_e", "r_e", "inflation", "cr", "mys", "fr", 
                 "ms", sapply(1:20, function(x){sprintf("param_%i", x)}))
dates <- zoo::index(y)
y <- as.data.frame(y, row.names = NULL)

head(y, 10)
```

```{r, rw_latent_lpd_pomp_model, eval=FALSE}
# pomp model for random walk latent lpd
rw_latent_lpd_pomp <- pomp::pomp(
    data = y[, c(1, 2)],
    times = "time", t0 = 1,
    rinit = function(e_lpd_0, ...) {
        return(c(e_lpd = e_lpd_0))
    },
    rprocess = pomp::discrete_time(
        pomp::Csnippet(
            "e_lpd = e_lpd + rnorm(0, exp(sigma_u));"
        ), 
        delta.t = 1
    ),
    dmeasure = rw_latent_lpd_dmeasure,
    statenames = "e_lpd",
    paramnames = c("e_lpd_0", "sigma_u", "sigma_e"),
    covar = pomp::covariate_table(y[, -c(2, 6, 7, 8, 9)], times = "time"),
    covarnames = colnames(y[, -c(1, 2, 6, 7, 8, 9)])
)
```

```{r, nelder_mead_optimization, eval=FALSE}
# need to use log sigma_u and sigma_e!
theta <- c(e_lpd_0 = 3.5, sigma_u = log(0.05), sigma_e = log(0.05))

# Nelder Mead optimization
rw_latent_lpd_optim_result <- optim(
    par = theta, 
    fn = function(par){
        print(par)
        return(-pomp::logLik(pomp::pfilter(
            rw_latent_lpd_pomp, params = par, Np = 1000
        )))
    },
)

theta_result <- rw_latent_lpd_optim_result$par
theta_result <- c(e_lpd_0 = 3.373877, sigma_u = -3.202661, sigma_e = -4.690985)

particle_filter_result <- pomp::pfilter(
  rw_latent_lpd_pomp, params = theta_result, Np = 1000, 
  pred.mean = TRUE, pred.var = TRUE, 
  filter.mean = TRUE, filter.traj = TRUE, 
  save.states = TRUE, verbose = FALSE
)
pomp::logLik(particle_filter_result)

plot(dates, y$lpd, type = "l", xlab = "t", ylab = "lpd")
lines(dates, particle_filter_result@filter.mean[1, ], col = "red")
legend(
  "topleft",
  col = c("black", "red"),
  lty = c(1, 1),
  legend = c("lpd", "latent_lpd")
)
```

```{r, rw_model_pmmh, eval=FALSE}
theta <- c(e_lpd_0 = 3.5, sigma_u = log(0.05), sigma_e = log(0.05))
pmmh_rw_latent_lpd_model <- pomp::pmcmc(
  rw_latent_lpd_pomp,
  Np = 500,
  Nmcmc = 1000,
  params = theta,
  proposal = pomp::mvn.diag.rw(
    c(e_lpd_0 = 0.03, sigma_u = 0.03, sigma_e = 0.03)
  ),
  verbose = TRUE
)
```

```{r, iterated_filtering, eval=FALSE}
# profile for sigma_e
profile_params <- pomp::profile_design(
    sigma_e = seq(log(0.001), log(0.05), length.out = 11),
    lower = c(e_lpd_0 = 3.0, sigma_u = log(0.01)),
    upper = c(e_lpd_0 = 4.0, sigma_u = log(0.1)),
    nprof = 20
)


# store profile for e_lpd_0
pomp::bake("simple_sigma_e_profile.rds", {

  library(doRNG)
  library(foreach)
  registerDoRNG(1598260027L)
  
  cl <- parallel::makeCluster(4)
  doParallel::registerDoParallel(cl)
  
  result <- foreach(
    p = iterators::iter(profile_params, "row"), .combine = bind_rows, 
    .inorder = FALSE
  ) %dopar% {
    tic <- Sys.time()
    source(here::here("R", "pd_pomp.R"))
    
    library(pomp)
    library(tidyverse)
    
    rw_latent_lpd_pomp %>% 
      mif2(
        params = p,
        Nmif = 25, 
        rw.sd = rw.sd(
          e_lpd_0 = ivp(0.05), sigma_e = 0.04, sigma_u = 0.04
        ),
        Np = 250,
        cooling.type = "geometric",
        cooling.fraction.50 = 0.5
      ) -> mf
    
    ## Runs 10 particle filters to assess Monte Carlo error in likelihood
    pf <- replicate(10, pfilter(mf, Np = 250))
    ll <- sapply(pf, logLik)
    ll <- logmeanexp(ll, se = TRUE)
    
    toc <- Sys.time()
    etime <- toc - tic
    units(etime) <- "hours"
    
    data.frame(
      as.list(coef(mf)),
      loglik = ll[1],
      loglik.se = ll[2],
      etime = as.numeric(etime)
    )
  }
  
  parallel::stopCluster(cl)
  
  result
}) %>% filter(is.finite(loglik)) -> sigma_e_prof

pairs(
  ~ loglik + e_lpd_0 + sigma_e + sigma_u,
  data = sigma_e_prof
)
```

```{r, test_pmcmc, eval=FALSE}
covars <- y[, -2]
covars[1:(nrow(y)-1), colnames(y)[5:9]] <- covars[2:nrow(y), colnames(y)[5:9]]

# pomp model for covariate latent lpd
covariate_latent_lpd_pomp <- pomp::pomp(
    data = y[, c(1, 2)],
    times = "time", t0 = 1,
    rinit = function(mu, ...) {
        return(c(e_lpd = mu))
    },
    rprocess = pomp::discrete_time(
        pomp::Csnippet(
            "
            e_lpd = (
              tanh(phi) * e_lpd
              + beta_1 * cr
              + beta_2 * mys
              + beta_3 * fr
              + beta_4 * ms
              + rnorm(0, exp(sigma_u))
            );
            "
        ), 
        delta.t = 1
    ),
    dmeasure = rw_latent_lpd_dmeasure,
    statenames = "e_lpd",
    paramnames = c("mu", "sigma_u", "sigma_e", "beta_1", 
                   "beta_2", "beta_3", "beta_4", "phi"),
    covar = pomp::covariate_table(covars, times = "time"),
    covarnames = colnames(covars[, -1])
)

theta <- c(
  mu = 3.5,
  phi = atanh(0.95),
  beta_1 = 0,
  beta_2 = 0,
  beta_3 = 0,
  beta_4 = 0,
  sigma_e = log(0.05),
  sigma_u = log(0.05)
)

pf <- pomp::pfilter(
  covariate_latent_lpd_pomp, params = theta, Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf)

data <- data.frame(
  e_lpd = particle_filter_result@filter.mean[1, ],
  cr = y$cr, mys = y$mys, fr = y$fr, ms = y$ms
)
a <- ARDL::ardl(e_lpd ~ cr + mys + fr + ms, data = data, 
                order = c(1, 0, 0, 0, 0))
summary(a)

pmmh_test <- pomp::pmcmc(
  covariate_latent_lpd_pomp,
  Nmcmc = 1000,
  Np = 1000,
  proposal = pomp::mvn.diag.rw(
    c(mu = 0.03, sigma_e = 0.03, sigma_u = 0.03, beta_1 = 0.001,
      beta_2 = 0.001, beta_3 = 0.001, beta_4 = 0.001, phi = 0.03)
  ),
  params = theta,
  verbose = TRUE
)

pf2 <- pomp::pfilter(
  covariate_latent_lpd_pomp, 
  params = colMeans(pmmh_test@traces[, 3:(2+length(theta))]), 
  Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf2)

pf2 <- pomp::pfilter(
  covariate_latent_lpd_pomp, 
  params = pmmh_test@traces[nrow(pmmh_test@traces), 3:(2+length(theta))], 
  Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf2)

plot(dates, y$lpd, type = "l", xlab = "t", ylab = "lpd")
lines(dates, pf2@filter.mean[1, ], col = "green")
```

```{r, eval=FALSE}
# plot discounted difference between d_e and r_e
e <- vector("numeric", length = 205)
for (i in 1:205) {
  A_mat <- matrix(params[i, ], nrow = 4, ncol = 5, byrow = TRUE)
  A_mat <- rbind(A_mat, c(rep(0, ncol(A_mat) - 1), 1))
  rho_t <- 1 / (1 + exp(-particle_filter_result@filter.mean[1, i]))
  k_t <- -log(rho_t) - ((1 - rho_t) * log((1 / rho_t) - 1))
  e[i] <- (
      t(c(0, 1, -1, 0, 0))
      %*% A_mat
      %*% solve(diag(5) - rho_t * A_mat)
      %*% c(y$lpd[i], y$d_e[i], y$r_e[i], y$inflation[i], 1)
  )
}
plot(e, type = "l")
```

```{r, eval=FALSE}
# regression d_e on latent_lpd
y1 <- y$d_e - y$r_e
m1 <- lm(y1[2:length(y1)] ~ particle_filter_result@filter.mean[1, 1:(length(y1)-1)])
summary(m1)

y2 <- y$d_e
m2 <- lm(y2[2:length(y2)] ~ particle_filter_result@filter.mean[1, 1:(length(y2)-1)])
summary(m2)

y3 <- y$r_e
m3 <- lm(y3[2:length(y3)] ~ particle_filter_result@filter.mean[1, 1:(length(y3)-1)])
summary(m3)

m4 <- lm(y2[2:length(y2)] ~ y$lpd[1:(length(y2)-1)])
summary(m4)

# ARDL test
d <- data.frame(d_e = y2[2:length(y2)], 
                e_lpd = particle_filter_result@filter.mean[1, 1:(length(y2)-1)])
a <- ARDL::ardl(d_e ~ e_lpd, data = d, order = c(1, 0))
summary(a)
```
