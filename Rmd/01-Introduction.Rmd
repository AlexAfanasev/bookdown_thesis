---
output: pdf_document
editor_options: 
  chunk_output_type: console
---

\mainmatter

# Introduction {#intro}

Discounted cash flow models are used widely in the financial industry for determining the present value of an investment. Campbell and Shiller present, in their article [@campbell_shiller_paper], a log linear approximation of the present value formulation. They show that the current log price-dividend ratio (PD) is approximately the sum of a constant plus the difference of discounted future log returns and discounted future log dividend growth. Furthermore, they use the long term mean of the PD for computing the present values.

A major assumption for this step is the stationarity of the PD that has been tested and evaluated in [@dog_bark_paper; @h2_paper]. Contrary to the assumption made by Campbell and Shiller, the results indicate that the PD is indeed nonstationary and therefore the long term mean does not exist. Based on these findings there have been multiple suggestions for modeling the PD as a pnonstationary process. As a common similarity partially observed Markov processes, also called state-space models, have been proposed. There the mean of the PD will be handled as a latent process. As an example the latent mean can be modeled with discrete shifts as proposed in [@van_nieuwerburgh_paper]. However, this project will be based mostly on the results depicted in [@h2_paper] where a nonlinear state space model has been applied and estimated using the sequential Monte Carlo technique in combination with the Nelderâ€“Mead optimization method [@nelder_mead]. The latent mean has been modeled as a random walk and as a autoregressive process of order one. Moreover, possible determinants of this latent mean have been studied within a cointegration analysis.

In the last years further advances in estimation procedures for nonlinear state-space models have been made. Contrary to the applied Nelder-Mead routine in [@h2_paper], this project will focus on a Bayesian approach. Of particular interest will be the recently developed particle marginal Metropolis Hastings procedure by [@doucet]. Additionally, further state process extensions with covariates for the latent mean of the PD will be tested.

All in all, this Master's thesis will have the following goals:

1. compare likelihood based (nelder mead) with mcmc approach --> simulation

2. apply different state process including economic link to financial markets using mcmc approach --> compare models

Chapter two will start with a review of the existing literature. Namely already conducted research around the latent mean of the PD, new inferential procedures surrounding nonlinear state space models and corresponding software will be inspected. The third chapter will present the basic structure of partially observed Markov processes. There, likelihood based and Bayesian approaches will be explained. In chapter four a simulation study that is closely related to the empirical application will be conducted. The likelihood based approach, using the Nelder-Mead algorithm, will be compared with the PMMH approach using different prior specifications. Chapter five will present the results of the empirical application. The latent mean of the PD will be fitted and the state and observation process parameters estimated. Besides that, the effect of further macroeconomic variables will be tested and state processes containing these covariates evaluated. Finally, the last chapter will be the conclusion and summarize everything.

<!-- **Content:** -->

<!-- - Describe Goals of thesis and relation to previous work (Determinants of the price dividend ratio) -->

<!--     - Extend estimation of latent state (mean price dividend ratio) by including possible economic determinants -->

<!-- - Describe the purpose of the MCMC Extension (benefits and possible disadvantages) -->

<!--     - Advantage because of short time series (prior information from previous study)??? -->

<!--     - verification with simulation study (linear and nonlinear case) -->
    
```{r, introduction_source, eval=FALSE, echo=FALSE}
source(here::here("R", "pd_pomp.R"), local = knitr::knit_global())
source(here::here("R", "prepare_raw_data.R"), local = knitr::knit_global())
```

<!-- ## Model -->

<!-- **Measurement:** -->

<!-- $$\eta_{t} = \frac{k_{t}}{1-\rho_{t}}+\sum_{i\;=\;1}^{\infty}\rho^{i-1}_{t}\tilde{E}[\Delta d^{e}_{t+i}-r_{t+i}^{e}] + \epsilon_{t}$$ -->

<!-- $$\epsilon_{t} \sim N(0, \sigma_{\epsilon}^2)$$ -->

<!-- $$\rho_{t} = \frac{1}{1+exp(-\tilde{\eta_{t}})}$$ -->

<!-- $$k_{t} = -ln(\rho_{t})-(1-\rho_{t})ln\bigg(\frac{1}{\rho_{t}} - 1\bigg)$$ -->

<!-- **State:** -->

<!-- $$\tilde{\eta}_{t} = \tilde{\eta}_{t-1} + u_{t}$$ -->

<!-- **Model with covariates:** -->

<!-- $$\tilde{\eta}_{t} = \beta_{0} + \beta_{1}\tilde{\eta}_{t-1} + \beta_{2}cr_{t-1} + \beta_{3}my_{t-1} + \beta_{4}fr_{t-1} + \beta_{5}ms_{t-1} + u_{t}$$ -->

<!-- $$u_{t} \sim N(0, \sigma_{u}^2)$$ -->

<!-- ## Estimation -->

<!-- **Data:** -->

<!-- - *lpd*: log price dividend ratio -->
<!-- - *d_e*: excess dividends -->
<!-- - *r_e*: excess returns -->
<!-- - *infl*: inflation -->
<!-- - *cr*: consumption risk -->
<!-- - *my*: middle aged to young ratio -->
<!-- - *fr*: effective federal funds rate -->
<!-- - *ms*: log real money supply m1 -->
<!-- - *gdp*: log gdp -->

```{r, rw_latent_lpd_pomp_model, eval=FALSE, echo=FALSE}
# pomp model for random walk latent lpd
rw_latent_lpd_pomp <- pomp::pomp(
    data = y[, c(1, 2)], times = "time", t0 = 0,
    rinit = function(e_lpd_0, ...) {
        return(c(e_lpd = e_lpd_0))
    },
    rprocess = pomp::discrete_time(
        pomp::Csnippet(
            "e_lpd = e_lpd + rnorm(0, exp(sigma_u));"
        ), 
        delta.t = 1
    ),
    dmeasure = rw_latent_lpd_dmeasure,
    statenames = "e_lpd",
    paramnames = c("e_lpd_0", "sigma_u", "sigma_e"),
    covar = pomp::covariate_table(rbind(0, y[, -c(2, 6, 7, 8, 9)]), 
                                  times = "time"),
    covarnames = colnames(rbind(0, y[, -c(1, 2, 6, 7, 8, 9)]))
)
```

```{r, nelder_mead_optimization, eval=FALSE, echo=FALSE}
# need to use log sigma_u and sigma_e!
theta <- c(e_lpd_0 = 3.6, sigma_u = log(0.05), sigma_e = log(0.05))

# Nelder Mead optimization
rw_latent_lpd_optim_result <- optim(
    par = theta, 
    fn = function(par){
        print(par)
        return(-pomp::logLik(pomp::pfilter(
            rw_latent_lpd_pomp, params = par, Np = 250
        )))
    },
)

theta_result <- rw_latent_lpd_optim_result$par
# theta_result <- c(e_lpd_0 = 3.373877, sigma_u = -3.202661, sigma_e = -4.690985)

particle_filter_result <- pomp::pfilter(
  rw_latent_lpd_pomp, params = theta_result, Np = 1000, 
  pred.mean = TRUE, pred.var = TRUE, 
  filter.mean = TRUE, filter.traj = TRUE, 
  save.states = TRUE, verbose = FALSE
)
pomp::logLik(particle_filter_result)

plot(dates, y$lpd, type = "l", xlab = "t", ylab = "lpd")
lines(dates, particle_filter_result@filter.mean[1, ], col = "red")
# lines(dates, pomp::filter.traj(particle_filter_result)[1, 1, ], col = "green")
legend(
  "topleft",
  col = c("black", "red"),
  lty = c(1, 1),
  legend = c("lpd", "latent_lpd")
)
```

```{r, rw_model_pmmh, eval=FALSE, echo=FALSE}
theta <- c(e_lpd_0 = 3.5, sigma_u = log(0.05), sigma_e = log(0.05))
pmmh_rw_latent_lpd_model <- pomp::pmcmc(
  rw_latent_lpd_pomp,
  Np = 250,
  Nmcmc = 1000,
  params = theta,
  proposal = pomp::mvn.diag.rw(
    c(e_lpd_0 = 0.03, sigma_u = 0.03, sigma_e = 0.03)
  ),
  verbose = FALSE
)
# pomp::plot(pmmh_rw_latent_lpd_model)
a <- pmmh_rw_latent_lpd_model@filter.traj[1, , ]
plot(dates, y$lpd, type = "l")
lines(dates, colMeans(a)[-1], col = "red")
q <- apply(a, 2, quantile, probs = c(0.025, 0.975))
lines(dates, q[1, -1], col = "red", lty = 2)
lines(dates, q[2, -1], col = "red", lty = 2)
```

```{r, test_pmcmc, eval=FALSE, echo=FALSE}
source(here::here("R", "covars.R"), local = knitr::knit_global())

# pomp model for covariate latent lpd
covariate_latent_lpd_pomp <- pomp::pomp(
    data = y[, c(1, 2)],
    times = "time", t0 = 0,
    rinit = function(e_lpd_0, ...) {
        return(c(e_lpd = e_lpd_0))
    },
    rprocess = pomp::discrete_time(
        pomp::Csnippet(
            "
            e_lpd = (
              beta_0
              + tanh(phi) * e_lpd
              + beta_1*cr
              + beta_2*mys
              + beta_3*fr
              + beta_4*ms
              + beta_5*gdp
              + rnorm(0, exp(sigma_u))
            );
            "
        ),
        delta.t = 1
    ),
    dmeasure = rw_latent_lpd_dmeasure,
    statenames = c("e_lpd"),
    paramnames = c("sigma_u", "sigma_e", "phi", "e_lpd_0", "beta_0",
                   "beta_1", "beta_2", "beta_3", "beta_4", "beta_5"),
    covar = pomp::covariate_table(covars, times = "time"),
    covarnames = colnames(covars[, -1])
)

theta <- c(
  e_lpd_0 = 3.5,
  phi = atanh(0.95),
  beta_0 = 0.175,
  beta_1 = 0,
  beta_2 = 0,
  beta_3 = 0,
  beta_4 = 0,
  beta_5 = 0,
  sigma_e = log(0.05),
  sigma_u = log(0.05)
)

covar_latent_lpd_optim_result <- optim(
    par = theta, 
    fn = function(par){
        print(par)
        return(-pomp::logLik(pomp::pfilter(
            covariate_latent_lpd_pomp, params = par, Np = 500
        )))
    },
)

pf <- pomp::pfilter(
  covariate_latent_lpd_pomp, params = covar_latent_lpd_optim_result$par, 
  Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf)

data <- data.frame(
  e_lpd = particle_filter_result@filter.mean[1, ],
  cr = y$cr, mys = y$mys, fr = y$fr, ms = y$ms
)
a <- ARDL::ardl(e_lpd ~ cr + mys + fr + ms, data = data, 
                order = c(1, 0, 0, 0, 0))
summary(a)

m <- lm(
  e_lpd ~ 1 + cr + mys + fr + ms, data = data
)
summary(m)

beta <- as.vector(coef(a))
theta <- c(
    e_lpd_0 = 3.5,
    phi = atanh(beta[2]),
    beta_0 = beta[1], 
    beta_1 = beta[3],
    beta_2 = beta[4],
    beta_3 = beta[5],
    beta_4 = beta[6],
    sigma_e = -4.8,
    sigma_u = -3.1
)

# how to set proposal jump size
simulation_result <- pomp::bake(
  "pmmh_test.rds",
  {
    doRNG::registerDoRNG(1598260027L)
    cl <- parallel::makeCluster(4)
    doParallel::registerDoParallel(cl)
    results <- foreach::`%dopar%`(
      foreach::foreach(i = 1:4),
      {
        source(here::here("R", "pd_pomp.R"), local = knitr::knit_global())
        pomp::pmcmc(
          covariate_latent_lpd_pomp,
          Nmcmc = 1000,
          Np = 250,
          proposal = pomp::mvn.rw.adaptive(
            c(e_lpd_0 = 0.03, sigma_e = 0.03, sigma_u = 0.03,  
              beta_0 = 0.005, beta_1 = 0.005, beta_2 = 0.005, beta_3 = 0.005, 
              beta_4 = 0.005, 
              phi = 0.03), 
            scale.start = 1,
            scale.cooling = 0.9,
            max.scaling = 10,
            shape.start = 50
          ),
          params = theta
        )
      }
    )
    parallel::stopCluster(cl)
    results
  }
)

pf2 <- pomp::pfilter(
  covariate_latent_lpd_pomp, 
  params = colMeans(pmmh_test@traces[, 3:(2+length(theta))]), 
  Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf2)

pf2 <- pomp::pfilter(
  covariate_latent_lpd_pomp, 
  params = pmmh_test@traces[nrow(pmmh_test@traces), 3:(2+length(theta))], 
  Np = 1000,
  filter.mean = TRUE
)
pomp::logLik(pf2)

plot(dates, y$lpd, type = "l", xlab = "t", ylab = "lpd")
lines(dates, pf2@filter.mean[1, ], col = "green")
```

```{r, eval=FALSE, echo=FALSE}
# plot discounted difference between d_e and r_e
e <- vector("numeric", length = 205)
for (i in 1:205) {
  A_mat <- matrix(params[i, ], nrow = 4, ncol = 5, byrow = TRUE)
  A_mat <- rbind(A_mat, c(rep(0, ncol(A_mat) - 1), 1))
  rho_t <- 1 / (1 + exp(-particle_filter_result@filter.mean[1, i]))
  k_t <- -log(rho_t) - ((1 - rho_t) * log((1 / rho_t) - 1))
  e[i] <- (
      t(c(0, 1, -1, 0, 0))
      %*% A_mat
      %*% solve(diag(5) - rho_t * A_mat)
      %*% c(y$lpd[i], y$d_e[i], y$r_e[i], y$inflation[i], 1)
  )
}
plot(e, type = "l")
```

```{r, eval=FALSE, echo=FALSE}
# regression d_e on latent_lpd
y1 <- y$d_e - y$r_e
m1 <- lm(y1[2:length(y1)] ~ particle_filter_result@filter.mean[1, 1:(length(y1)-1)])
summary(m1)

y2 <- y$d_e
m2 <- lm(y2[2:length(y2)] ~ particle_filter_result@filter.mean[1, 1:(length(y2)-1)])
summary(m2)

y3 <- y$r_e
m3 <- lm(y3[2:length(y3)] ~ particle_filter_result@filter.mean[1, 1:(length(y3)-1)])
summary(m3)

m4 <- lm(y2[2:length(y2)] ~ y$lpd[1:(length(y2)-1)])
summary(m4)

# ARDL test
d <- data.frame(d_e = y2[2:length(y2)], 
                e_lpd = particle_filter_result@filter.mean[1, 1:(length(y2)-1)])
a <- ARDL::ardl(d_e ~ e_lpd, data = d, order = c(1, 0))
summary(a)
```
