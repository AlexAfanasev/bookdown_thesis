---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Empirical application {#application}

For the empirical application the presented particle marginal Metropolis Hastings procedure will be applied to the price-dividend ratio. This application will be an extension of the presented results and procedures in [@h2_paper]. Besides applying the Bayesian approach as an alternative, further possible specifications of the latent state process will be inspected. First the steps for deriving the state-space model will be explained.

## Model implementation

Starting from the basic definition of the total log-return at time $t+1$, $r_{t+1} = \ln(P_{t+1} + D_{t+1}) - \ln(P_{t})$ with price $P_{t}$ and dividend $D_t$, the log-return can be reformulated as a nonlinear function of the log price-dividend ration $\eta_t$. First subtracting $r_{t+1}$ from itself yields
\begin{equation*}
\begin{split}
0 &= \ln\Bigg(\frac{P_t}{P_{t+1} + D_{t+1}}\frac{P_{t+1} + D_{t+1}}{P_{t}}\Bigg)
\end{split}
\end{equation*}
then adding $\eta_t$ to both sides of the equation
\begin{equation*}
\begin{split}
\eta_{t} &= \ln\Bigg(\frac{P_t}{D_t}\frac{P_{t+1} + D_{t+1}}{P_{t}}\Bigg) - r_{t+1} = \ln\Bigg(\Bigg(1 + \frac{P_{t+1}}{D_{t+1}}\Bigg)\frac{D_{t+1}}{D_{t}}\Bigg) - r_{t+1}
\end{split}
\end{equation*}
and simplifying the above yields
\begin{equation*}
\begin{split}
\eta_{t} &= \ln(1 + \text{exp}(\eta_{t+1})) - r_{t+1} + \Delta d_{t+1} \\
r_{t+1} &= -\eta_{t} + \ln(1 + \text{exp}(\eta_{t+1})) + \Delta d_{t+1}
\end{split}
\end{equation*}
Here, $\Delta d_{t+1} = \ln(D_{t+1}) - \ln(D_t)$ represents the log dividend growth. Applying a first order Taylor expansion around the fixed steady state $\bar{\eta}$ yields a linear approximation
\begin{equation}
\begin{split}
r_{t+1} &\approx -\eta_{t} + \ln(1 + \text{exp}(\bar{\eta})) + \Delta d_{t+1} + \frac{1}{1 + \text{exp}(-\bar{\eta})}(\eta_{t+1}-\bar{\eta}) \\
&\approx k -\eta_{t} + \rho\eta_{t+1} + \Delta d_{t+1}
\end{split}
\end{equation}
with $\rho$ being specified as
\begin{align}
\rho &= \frac{1}{1+\text{exp}(-\bar{\eta})} & \Longleftrightarrow && \bar{\eta} &= -\ln\Bigg(\frac{1}{\rho} - 1\Bigg)
(\#eq:rho-spec)
\end{align}
and $k$ directly following from the above
\begin{equation}
\begin{split}
k &= \ln(1 + \text{exp}(\bar{\eta})) - \bar{\eta}\frac{1}{1 + \text{exp}(-\bar{\eta})} \\
&= \ln\Bigg(1 + \text{exp}\Bigg(-\ln\Bigg(\frac{1}{\rho} - 1\Bigg)\Bigg)\Bigg) + \ln\Bigg(\frac{1}{\rho} - 1\Bigg)\frac{1}{1 + \text{exp}\Big(\ln\Big(\frac{1}{\rho} - 1\Big)\Big)} \\
&= -\ln(1 - \rho) + \rho\ln\Bigg(\frac{1}{\rho} - 1\Bigg) \\
&= -\ln(\rho) - (1 - \rho)\ln\Bigg(\frac{1}{\rho} - 1\Bigg) 
(\#eq:k-spec)
\end{split}
\end{equation}
Previous empirical applications typically assumed a constant parameter $\bar{\eta}$, as in [@campbell_paper]. However, the results presented in [@h2_paper] deliver evidence for a gradually time-varying mean of the log price-dividend ratio. By allowing this time variation $k$ and $\rho$ become also time-varying. Hence, the corresponding parameters $k_t$ and $\rho_t$ are obtained from \@ref(eq:rho-spec) and \@ref(eq:k-spec)
\begin{equation}
\begin{split}
\rho_t &= \frac{1}{1+\text{exp}(-\tilde{\eta}_t)} \\
k_t &= -\ln(\rho_t) - (1 - \rho_t)\ln\Bigg(\frac{1}{\rho_t} - 1\Bigg)
\end{split}
\end{equation}
with $\tilde{\eta}_t$ denoting the time varying local mean for the Taylor approximation. Therefore, the log price-dividend ratio has the following specification
\begin{equation}
\begin{split}
\eta_{t} &\approx k_t - r_{t+1} + \rho_t\eta_{t+1} + \Delta d_{t+1}
(\#eq:lpd-spec)
\end{split}
\end{equation}
Similar approximations as in [@van_nieuwerburgh_paper] are adopted: $\mathbb{E}_t[\rho_{t+i}]\approx\rho_t$, $\mathbb{E}_t[k_{t+i}]\approx\;k_t$ and $\mathbb{E}_t[\rho_{t+i}\eta_{t+1+i}]\approx\mathbb{E}_t[\rho_{t+i}]\mathbb{E}_t[\eta_{t+1+i}]$. The present value formulation of the log price-dividend ratio can then be concluded by taking the conditional expectation and iterating equation \@ref(eq:lpd-spec) forward
\begin{equation}
\begin{split}
\eta_{t} &\approx k_t - \mathbb{E}_t[r_{t+1}] + \rho_t\mathbb{E}_t[\eta_{t+1}] + \mathbb{E}_t[\Delta d_{t+1}] \\
 &\approx k_t - \mathbb{E}_t[r_{t+1}] + \rho_t\mathbb{E}_t[k_{t+1} - r_{t+2} + \rho_{t+1}\eta_{t+2} + \Delta d_{t+2}] + \mathbb{E}_t[\Delta d_{t+1}] \\
 &\approx \cdots \\
 &\approx \frac{k_t}{1-\rho_t} + \sum_{i=1}^{\infty}\rho_t^{i-1}\mathbb{E}_t[\Delta d_{t+i}^e - r_{t+i}^e] + \lim\limits_{i \rightarrow \infty}\rho_t^i\mathbb{E}_t[\eta_{t+i}]
(\#eq:present-value)
\end{split}
\end{equation}
Here, the excess dividend growth $\Delta d_{t}^e = \Delta d_t - r^f_t$ and return $r_t^e = r_t - r_t^f$ are used with $r^f_t$ being the risk-free interest rate.

The state-space model will be used to estimate the latent mean $\tilde{\eta}_t$. As in [@h2_paper], the present value formulation \@ref(eq:present-value) will be used as the observation process by adding an error term $\epsilon_t \sim\mathcal{N}(0, \sigma_{\epsilon}^2)$ that captures rational bubbles, approximation errors and other influences in $\lim\limits_{i \rightarrow \infty}\rho_t^i\mathbb{E}_t[\eta_{t+i}]$.
\begin{equation}
\eta_{t} = \frac{k_t}{1-\rho_t} + \sum_{i=1}^{\infty}\rho_t^{i-1}\mathbb{\tilde{E}}_t[\Delta d_{t+i}^e - r_{t+i}^e] + \epsilon_t
 (\#eq:observation-process)
\end{equation}
A low dimensional vector autoregressive (VAR) model of order $1$ will be used for the objective expectations $\mathbb{\tilde{E}}_t$ conditional on information available at the end of $t$. This approach was first proposed in [@campbell_shiller_paper]. The VAR model will be comprised of the log price-dividend ratio $\eta_t$, excess dividend growth $\Delta d_t^e$, excess return $r_t^e$ and inflation $\pi_t$.

Assuming the following VAR model
\begin{equation}
y_t = \begin{pmatrix} \eta_t \\ \Delta d_t^e \\ r_t^e \\ \pi_t \end{pmatrix} = \alpha + Ay_{t-1} + v_t
 (\#eq:ex-ante-expectations-var-model)
\end{equation}
and the following reparametrization by stacking the vector of constants $\alpha$ on to the parameter matrix $A$
\begin{equation}
y_t = \begin{pmatrix} \eta_t \\ \Delta d_t^e \\ r_t^e \\ \pi_t \\ 1 \end{pmatrix} = \left(
\begin{array}{c|c}
        A & \alpha \\
        \hline
        0 & 1\\
\end{array}
\right)y_{t-1} + \begin{pmatrix}v_t \\ 0\end{pmatrix} = B y_{t-1} + \begin{pmatrix}v_t \\ 0\end{pmatrix}
\end{equation}
the discounted expectations can be evaluated using the vector $h = \begin{pmatrix} 0 & 1 & -1 & 0 & 0\end{pmatrix}^T$
\begin{equation}
\begin{split}
\sum_{i=1}^{\infty}\rho_t^{i-1}\mathbb{\tilde{E}}_t[\Delta d_{t+i}^e - r_{t+i}^e] &= \sum_{i=1}^{\infty}\rho_t^{i-1}h^TB^iy_{t} \\
& = h^TB\sum_{i=0}^{\infty}\rho_t^{i}B^iy_{t} = h^TB(I_5 -\rho_t B)^{-1}y_t
 (\#eq:ex-ante-expectations)
\end{split}
\end{equation}
Similar to [@h2_paper] a adaptive approach will be used for the choice of VAR sample size. Starting at the forecasting origin, observation $t = 30$, VAR models with samples $\Omega_{t,\omega} = \{\eta_\tau, \Delta d^e_\tau, r_\tau^e, \pi_\tau\;|\;\tau = t-\omega+1, ..., t\}$ and varying lengths $\omega = (10, ..., 30)$ will be fitted. The selection criterion will be the root mean squared error of the last $5$ in sample observations of the excess dividend rate and excess return, $\{\Delta d_m^e - r_m^e\}^t_{t-9}$. Additionally, the stability of each VAR model will be checked, at each length $\omega$, by inspecting that all eigenvalues of $A$ have modulus less than 1. If this requirement is violated the specific VAR model will be discarded. The VAR model with $\omega = 10$ will be used if at a specific time point $t$ all VAR models violate the stability requirement.

The empirical application will be conducted on quarterly data for the S&P 500 starting at the 31st of December 1970 up until the 30th of September 2020.

## Random walk state process

Firstly, the state-space model with a random walk state process will be analyzed. The latent process follows
\begin{equation}
\begin{split}
\tilde{\eta}_t &= \tilde{\eta}_{t-1} + u_t \\
u_t &\sim \mathcal{N}(0, \sigma_u^2)
(\#eq:basic-model-state-process)
\end{split}
\end{equation}
The parameters of interest are $\theta = \begin{pmatrix} \tilde{\eta}_0 & \sigma_{\epsilon} & \sigma_{u}\end{pmatrix}^T$ with $\tilde{\eta}_0$ being the initial value . Similar to the simulation study uninformative setup, flat priors will be used for the parameters and initial value and equal parameter transformations will be applied
\begin{align*}
\sigma_\epsilon(\varsigma_\epsilon) &= \text{exp}(\varsigma_\epsilon) & \Longleftrightarrow && \varsigma_\epsilon(\sigma_\epsilon) &= \ln(\sigma_\epsilon) \\
\sigma_u(\varsigma_u) &= \text{exp}(\varsigma_u) & \Longleftrightarrow && \varsigma_\epsilon(\sigma_u) &= \ln(\sigma_u)
\end{align*}
Hence, after having applied the change of variable technique the prior specification for the hyperparameters $\{\varsigma_\epsilon, \varsigma_u\}$ becomes
\begin{equation}
\begin{split}
  p_{\varsigma_\epsilon}(\varsigma_\epsilon) &= \text{exp}(\varsigma_\epsilon) \\
  p_{\varsigma_u}(\varsigma_u) &= \text{exp}(\varsigma_u)
\end{split}
\end{equation}
For the PMMH procedure $3$ independent Markov chains with $M = 20000$ iterations and $J = 1000$ particles will be run and the starting parameter $\theta_0$ will be set to 
$$
\theta_0 = \begin{pmatrix}\tilde{\eta}_0^{(0)} \\ \varsigma_\epsilon^{(0)} \\ \varsigma_u^{(0)} \end{pmatrix} = \begin{pmatrix}3.5 \\ \ln(0.05) \\ \ln(0.05) \end{pmatrix}
$$
Furthermore, the parameter proposals will be generated using
$$
\theta_i^{*}\sim \mathcal{N}(\theta_i^{(m-1)}, 0.02^2)
$$
Figure \@ref(fig:basic-model-trace-plot) shows the trace plots for each parameter and each Markov chain. The first 5000 iterations have been dropped. Additionally, Figure \@ref(fig:basic-model-posterior-marginal-density) displays the Gaussian kernel density estimates for the random walk latent state model. The corresponding Table \@ref(tab:basic-model-setup) summarizes the inference results.

```{r, basic-model-setup, eval=TRUE, echo=FALSE, warning=FALSE, message=FALSE}
source(here::here("R", "prepare_raw_data.R"))
source(here::here("R", "model_comparison", "model_comparison_basic_model.R"))

library(tidyverse)

traces <- rbind(
        result[[1]]@traces[5000:20000, 3:5], 
        result[[2]]@traces[5000:20000, 3:5], 
        result[[3]]@traces[5000:20000, 3:5]
)
traces[, 2:3] <- exp(traces[, 2:3])

result_table <- data.frame(
  mean = colMeans(traces),
  median = apply(traces, 2, median),
  lower = apply(traces, 2, quantile, probs = 0.025),
  upper = apply(traces, 2, quantile, probs = 0.975)
)
rownames(result_table) <- c(
  "$\\tilde{\\eta}_0$", "$\\sigma_u$", "$\\sigma_\\epsilon$"
)
result_table <- round(result_table, 4)
opts <- options(knitr.kable.NA = "")
knitr::kable(
  result_table, 
  row.names = TRUE,
  col.names = c("Mean", "Median", "0.025\\%", "0.975\\%"),
  caption = "Random walk state model: PMMH parameter inference results", 
  booktabs = TRUE, escape = FALSE,
  linesep = "\\addlinespace", 
  align = rep("c", 4)
) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::kable_styling(latex_options = "hold_position")
```

```{r, basic-model-trace-plot, eval=TRUE, echo=FALSE, fig.align='center', fig.cap="Random walk state model: PMMH trace plot", fig.width=6, fig.height=8, warning=FALSE}
library(ggplot2)
library(gridExtra)

traces <- list(
  result[[1]]@traces[5000:20000, ], 
  result[[2]]@traces[5000:20000, ], 
  result[[3]]@traces[5000:20000, ]
)

# Plot theme:
p_theme <- theme(
  legend.position = "bottom", 
  legend.title = element_blank(), 
  legend.background = element_rect(fill = "transparent"),
  plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"),
  plot.title = element_text(hjust = 0.5, size = 8),
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8, angle = 0, vjust = 0.5)
)

# e_lpd_0
df <- data.frame(
  time = 1:nrow(traces[[1]]),
  value1 = traces[[1]][, 3], 
  value2 = traces[[2]][, 3], 
  value3 = traces[[3]][, 3]
)
df <- reshape2::melt(df, id.vars = "time")
p1 <- ggplot(data = df, aes(x = time, y = value)) +
  geom_line(aes(colour = variable)) + theme_light() +
  scale_colour_manual(
    values = c("red", "green", "blue"),
    labels = c("Chain 1", "Chain 2", "Chain 3")
  ) +
  labs(title = latex2exp::TeX("Trace Plot: \\textbf{$\\tilde{\\eta}_0$}"),
       x = "m", y = latex2exp::TeX("$\\tilde{\\eta}_0$")) +
  p_theme

# sigma_u
df <- data.frame(
  time = 1:nrow(traces[[1]]),
  value1 = traces[[1]][, 4], 
  value2 = traces[[2]][, 4], 
  value3 = traces[[3]][, 4]
)
df <- reshape2::melt(df, id.vars = "time")
df$value <- exp(df$value)
p2 <- ggplot(data = df, aes(x = time, y = value)) +
  geom_line(aes(colour = variable)) + theme_light() +
  scale_colour_manual(
    values = c("red", "green", "blue"),
    labels = c("Chain 1", "Chain 2", "Chain 3")
  ) +
  labs(title = latex2exp::TeX("Trace Plot: \\textbf{$\\sigma_u$}"),
       x = "m", y = latex2exp::TeX("$\\sigma_u$")) +
  p_theme

# sigma_epsilon
df <- data.frame(
  time = 1:nrow(traces[[1]]),
  value1 = traces[[1]][, 5], 
  value2 = traces[[2]][, 5], 
  value3 = traces[[3]][, 5]
)
df <- reshape2::melt(df, id.vars = "time")
df$value <- exp(df$value)
p3 <- ggplot(data = df, aes(x = time, y = value)) +
  geom_line(aes(colour = variable)) + theme_light() +
  scale_colour_manual(
    values = c("red", "green", "blue"),
    labels = c("Chain 1", "Chain 2", "Chain 3")
  ) +
  labs(title = latex2exp::TeX("Trace Plot: \\textbf{$\\sigma_\\epsilon$}"),
       x = "m", y = latex2exp::TeX("$\\sigma_\\epsilon$")) +
  p_theme

legend <- gtable::gtable_filter(ggplot_gtable(ggplot_build(p2)), "guide-box")

grid.arrange(
  p1 + theme(legend.position = "none"), 
  p2 + theme(legend.position = "none"), 
  p3 + theme(legend.position = "none"),
  ncol = 1, legend = legend, nrow = 4, 
  heights = c(1.1, 1.1, 1.1, 0.2)
)
```

```{r, basic-model-posterior-marginal-density, eval=TRUE, echo=FALSE, fig.align='center', fig.cap="Random walk state model: Gaussian kernel density estimates of the marginal posterior distributions", fig.width=6, fig.height=4, warning=FALSE}
traces <- rbind(
        result[[1]]@traces[5000:20000, 3:5], 
        result[[2]]@traces[5000:20000, 3:5], 
        result[[3]]@traces[5000:20000, 3:5]
)

# Plot theme:
p_theme <- theme(
  legend.justification = c(0, 1), legend.position = c(0, 1), 
  legend.title = element_blank(), 
  legend.background = element_rect(fill = "transparent"),
  plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"),
  plot.title = element_text(hjust = 0.5, size = 8),
  axis.title.x = element_text(size = 8),
  axis.title.y = element_text(size = 8, vjust = 0.5)
)

# e_lpd_0
df <- data.frame(time = 1:nrow(traces), e_lpd_0 = traces[, 1])
p1 <- ggplot(data = df, aes(x = e_lpd_0)) +
  geom_density(aes(x = e_lpd_0, colour = "Posterior", linetype = "Posterior"), 
               show.legend = FALSE) + 
  geom_vline(
    aes(xintercept = mean(traces[, 1]), 
        colour = "Posterior Mean", linetype = "Posterior Mean"), 
    show.legend = FALSE
  ) +
  stat_function(
    fun = function(...){1}, aes(colour = "Prior", linetype = "Prior")
  ) +
  theme_light() + p_theme + 
  scale_color_manual(
    values = c("Posterior" = "black", "Prior" = "#30914a", 
               "Posterior Mean" = "#2126b5"), 
    name = ""
  ) +
  scale_linetype_manual(
    values = c("Posterior" = 1, "Posterior Mean" = 3, "Prior" = 1), name = ""
  ) + 
  labs(title = latex2exp::TeX(
    "Marginal Posterior: \\textbf{$\\tilde{\\eta}_0$}"
  ), x = latex2exp::TeX("$\\tilde{\\eta}_0$"))

# sigma_u
df <- data.frame(time = 1:nrow(traces), sigma_u = exp(traces[, 2]))
p2 <- ggplot(data = df, aes(x = sigma_u)) +
  geom_density(aes(x = sigma_u, colour = "Posterior", linetype = "Posterior"), 
               show.legend = FALSE) + 
  geom_vline(
    aes(xintercept = mean(exp(traces[, 2])), 
        colour = "Posterior Mean", linetype = "Posterior Mean"), 
    show.legend = FALSE
  ) +
  stat_function(
    fun = function(...){1}, aes(colour = "Prior", linetype = "Prior")
  ) +
  theme_light() + p_theme + 
  scale_color_manual(
    values = c("Posterior" = "black", "Prior" = "#30914a", 
               "Posterior Mean" = "#2126b5"), 
    name = ""
  ) +
  scale_linetype_manual(
    values = c("Posterior" = 1, "Posterior Mean" = 3, "Prior" = 1), name = ""
  ) + 
  labs(title = latex2exp::TeX("Marginal Posterior: \\textbf{$\\sigma_u$}"),
       x = latex2exp::TeX("$\\sigma_u$"))

# sigma_epsilon
df <- data.frame(time = 1:nrow(traces), sigma_e = exp(traces[, 3]))
p3 <- ggplot(data = df, aes(x = sigma_e)) +
  geom_density(aes(x = sigma_e, colour = "Posterior", linetype = "Posterior"), 
               show.legend = FALSE) + 
  geom_vline(
    aes(xintercept = mean(exp(traces[, 3])), 
        colour = "Posterior Mean", linetype = "Posterior Mean"), 
    show.legend = FALSE
  ) +
  stat_function(
    fun = function(...){1}, aes(colour = "Prior", linetype = "Prior")
  ) +
  theme_light() + p_theme + 
  scale_color_manual(
    values = c("Posterior" = "black", "Prior" = "#30914a", 
               "Posterior Mean" = "#2126b5"), 
    name = ""
  ) +
  scale_linetype_manual(
    values = c("Posterior" = 1, "Posterior Mean" = 3, "Prior" = 1), name = ""
  ) + 
  labs(title = latex2exp::TeX(
    "Marginal Posterior: \\textbf{$\\sigma_\\epsilon$}"
  ), x = latex2exp::TeX("$\\sigma_\\epsilon$"))

get_legend <- function(myggplot){
  tmp <- ggplot_gtable(ggplot_build(myggplot))
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
  legend <- tmp$grobs[[leg]]
  return(legend)
}
legend <- get_legend(p2)

grid.arrange(
  p1 + theme(legend.position = "none"), 
  p2 + theme(legend.position = "none"), 
  p3 + theme(legend.position = "none"), 
  ncol = 2, legend = legend
)
```

Moreover, Figure \@ref(fig:basic-model-state-estimates) visualizes the marginal posterior mean for the latent state and corresponding $95\%$ pointwise credible intervals. One can directly see that the estimated latent mean captures structural changes in the log price-dividend ratio. 

```{r, basic-model-state-estimates, eval=TRUE, echo=FALSE, fig.align='center', fig.cap="Random walk state model: Latent state estimate", fig.width=6, fig.height=3.5, warning=FALSE}
traj <- rbind(
  result[[1]]@filter.traj[1, 5000:20000, ], 
  result[[2]]@filter.traj[1, 5000:20000, ],
  result[[3]]@filter.traj[1, 5000:20000, ]
)

df <- data.frame(time = dates, y = y$lpd, x = colMeans(traj)[-1])
df <- reshape2::melt(df, id.vars = "time")
q <- data.frame(
  time = dates,
  variable = "x",
  lower = apply(traj, 2, quantile, probs = 0.025)[-1],
  upper = apply(traj, 2, quantile, probs = 0.975)[-1]
)
ggplot(data = df, aes(x = time, y = value, group = variable)) +
  geom_line(aes(color = variable)) + 
  geom_ribbon(
    data = q, aes(x = time, ymin = lower, ymax = upper, fill = "red",
                  colour = variable),
    inherit.aes = FALSE, alpha = 0.25, show.legend = FALSE, linetype = 2,
    colour = "red", size = 0.25
  ) +
  theme_light() +
  scale_color_manual(
    values = c("black", "red"), 
    labels = unname(c(
      latex2exp::TeX("PD: $\\eta_t$"),
      latex2exp::TeX("Time-varying mean: $\\tilde{\\eta}_t$")
   ))
  ) +
  theme(
    legend.position = "bottom", 
    legend.title = element_blank(), 
    legend.background = element_rect(fill = "transparent"),
    plot.margin = unit(c(0.1,0.1,0.1,0.1), "cm"),
    plot.title = element_text(hjust = 0.5, size = 8),
    axis.title = element_blank()
  )
```
\newpage

## Cointegration analysis

The connection between economic fundamentals and financial markets will be studied by inspecting possible conomcic factors that drive the latent price-dividend ratio. In [@h2_paper] three long determinants of the latent mean of the price-dividend ratio have been found. These three factors form a cointegration relationship with the time-varying mean $\tilde{\eta}_t$: consumption risk, the demographic structure of the population and the dividend payout policy of firms.

As an initial step a similar cointegration analysis will be conducted by analyzing the effect of additional covariates. Besides including the previously established connection with consumption risk and the demographic of the population the following economic indicators will be analyzed, see \@ref(tab:cointegration-analysis-name-variables).

```{r, cointegration-analysis-name-variables, eval=TRUE, echo=FALSE}
result_table <- data.frame(
  description = c(
    "Consumption Risk",
    "Middle-Aged to Young Ratio",
    "Effective Federal Funds Rate",
    "Log Real M1 Money Supply (Trillions)",
    "Log Real GDP (10 Trillions)"
  )
)
rownames(result_table) <- c("$cr_t$", "$my_t$", "$fr_t$", "$ms_t$", "$gdp_t$")
opts <- options(knitr.kable.NA = "")
knitr::kable(
  result_table, 
  row.names = TRUE,
  col.names = c("Description"),
  caption = "Cointegration analysis: Covariates", 
  booktabs = TRUE, escape = FALSE,
  linesep = "\\addlinespace", 
  align = rep("l", 1)
) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::kable_styling(latex_options = "hold_position")
```

As has been proposed in [@consumption_risk] consumption risk has been computed as $cr_t = \ln({\sum_{i = 0}^{20}\left | co_{t-i} \right |})$ where $co_{t}$ is the residual from an AR(1) regression for real per capita consumption growth.

The impact of monetary policy has been of large interest in the asset pricing literature, see [@monetary_policy_asset_prices]. Here, the effective federal funds rate and the log real M1 money supply have been added for establishing a possible link between monetary policy and the latent price-dividend ratio. Furthermore, as an indicator of the state of the economy the log real GDP has been added.

Figure \@ref(fig:cointegration-analysis-plot-covariates) depicts the time-varying mean $\tilde{\eta}_t$ and all accompanying covariates. The effect of the COVID-19 pandemic are directly visible by inspecting the consumption risk $cr_t$, log M1 money stock $ms_t$ and log GDP $gdp_t$ time series. As a reaction to the shock that resulted in an sharp increase in consumption risk and large drop in GDP, the Federal Reserve intervened by lowering the federal funds rate, see [@fed_lower_funds_rate], and increasing the money stock by extending quantitative easing, see [@fed_qe].

```{r, cointegration-analysis-plot-covariates, eval=TRUE, echo=FALSE, fig.align='center', fig.cap="Cointegration analysis: Visualization of covariates", fig.width=6, fig.height=4, warning=FALSE}
traj <- rbind(
  result[[1]]@filter.traj[1, 5000:20000, ], 
  result[[2]]@filter.traj[1, 5000:20000, ],
  result[[3]]@filter.traj[1, 5000:20000, ]
)

# Plot theme:
p_theme <- theme(
  legend.justification = c(0, 1), legend.position = c(0, 1), 
  legend.title = element_blank(), 
  legend.background = element_rect(fill = "transparent"),
  plot.margin = unit(c(0.1, 0.1, 0.1, 0.1), "cm"),
  plot.title = element_text(hjust = 0.5, size = 8),
  axis.title = element_blank(),
  legend.key = element_rect(fill = NA)
)

# e_lpd
df <- data.frame(time = dates, y = colMeans(traj)[-1])
p1 <- ggplot(data = df, aes(x = time, y = y)) +
  geom_line() + theme_light() + p_theme +
  labs(
    title = latex2exp::TeX(
      "Time-varying mean of the PD: \\textbf{$\\tilde{\\eta}_t$}"
    )
  )

# cr
df <- data.frame(time = dates, cr = y$cr)
p2 <- ggplot(data = df, aes(x = time, y = cr)) +
  geom_line() + theme_light() + p_theme +
  labs(title = latex2exp::TeX("Consumption Risk: \\textbf{$cr_t$}"))

# mys
df <- data.frame(time = dates, mys = y$mys)
p3 <- ggplot(data = df, aes(x = time, y = mys)) +
  geom_line() + theme_light() + p_theme +
  labs(title = latex2exp::TeX("Middle-Aged to Young Ratio: \\textbf{$my_t$}"))

# fr
df <- data.frame(time = dates, fr = y$fr)
p4 <- ggplot(data = df, aes(x = time, y = fr)) +
  geom_line() + theme_light() + p_theme +
  labs(title = latex2exp::TeX("Effective Federal Funds Rate: \\textbf{$fr_t$}"))

# ms
df <- data.frame(time = dates, ms = y$ms)
p5 <- ggplot(data = df, aes(x = time, y = ms)) +
  geom_line() + theme_light() + p_theme +
  labs(title = latex2exp::TeX("Real M1 Money Supply: \\textbf{$ms_t$}"))

# Phi
# ms
df <- data.frame(time = dates, gdp = y$gdp)
p6 <- ggplot(data = df, aes(x = time, y = gdp)) +
  geom_line() + theme_light() + p_theme +
  labs(title = latex2exp::TeX("Real GDP: \\textbf{$gdp_t$}"))

grid.arrange(
  p1 + theme(legend.position = "none"), 
  p2 + theme(legend.position = "none"), 
  p3 + theme(legend.position = "none"), 
  p4 + theme(legend.position = "none"), 
  p5 + theme(legend.position = "none"), 
  p6 + theme(legend.position = "none"), 
  ncol = 2
)
```

Before investigating the cointegration relationship the individual variables will be characterized by means of the augmented Dickey-Fuller (ADF) test. Table \@ref(tab:cointegration-analysis-unit-root-tests) shows the test statistics for all variables. Furthermore, the test has been applied on the whole time series and the time series excluding the year 2020 with the developing COVID-19 pandemic.

```{r, cointegration-analysis-unit-root-tests, eval=TRUE, echo=FALSE}
traj <- rbind(
  result[[1]]@filter.traj[1, 5000:20000, ], 
  result[[2]]@filter.traj[1, 5000:20000, ],
  result[[3]]@filter.traj[1, 5000:20000, ]
)
e_lpd <- colMeans(traj)[-1]

# with corona
e_lpd1 <- urca::summary(urca::ur.df(e_lpd, type = "trend", lags = 1))
cr1 <- urca::summary(urca::ur.df(y$cr, type = "trend", lags = 1))
my1 <- urca::summary(urca::ur.df(y$mys, type = "trend", lags = 1))
fr1 <- urca::summary(urca::ur.df(y$fr, type = "trend", lags = 1))
ms1 <- urca::summary(urca::ur.df(y$ms, type = "trend", lags = 1))
gdp1 <- urca::summary(urca::ur.df(y$gdp, type = "trend", lags = 1))

d_e_lpd1 <- urca::summary(urca::ur.df(diff(e_lpd), type = "drift", lags = 1))
d_cr1 <- urca::summary(urca::ur.df(diff(y$cr), type = "drift", lags = 1))
d_my1 <- urca::summary(urca::ur.df(diff(y$mys), type = "drift", lags = 1))
d_fr1 <- urca::summary(urca::ur.df(diff(y$fr), type = "drift", lags = 1))
d_ms1 <- urca::summary(urca::ur.df(diff(y$ms), type = "drift", lags = 1))
d_gdp1 <- urca::summary(urca::ur.df(diff(y$gdp), type = "drift", lags = 1))
with_corona <- list(
  e_lpd1, cr1, my1, fr1, ms1, gdp1, d_e_lpd1, d_cr1, d_my1, d_fr1, d_ms1, d_gdp1
)

# without corona
e_lpd2 <- urca::summary(urca::ur.df(e_lpd[1:197], type = "trend", lags = 1))
cr2 <- urca::summary(urca::ur.df(y$cr[1:197], type = "trend", lags = 1))
my2 <- urca::summary(urca::ur.df(y$mys[1:197], type = "trend", lags = 1))
fr2 <- urca::summary(urca::ur.df(y$fr[1:197], type = "trend", lags = 1))
ms2 <- urca::summary(urca::ur.df(y$ms[1:197], type = "trend", lags = 1))
gdp2 <- urca::summary(urca::ur.df(y$gdp[1:197], type = "trend", lags = 1))

d_e_lpd2 <- urca::summary(urca::ur.df(diff(e_lpd[1:197]), type = "drift", lags = 1))
d_cr2 <- urca::summary(urca::ur.df(diff(y$cr[1:197]), type = "drift", lags = 1))
d_my2 <- urca::summary(urca::ur.df(diff(y$mys[1:197]), type = "drift", 
                                    lags = 1))
d_fr2 <- urca::summary(urca::ur.df(diff(y$fr[1:197]), type = "drift", lags = 1))
d_ms2 <- urca::summary(urca::ur.df(diff(y$ms[1:197]), type = "drift", lags = 1))
d_gdp2 <- urca::summary(urca::ur.df(diff(y$gdp[1:197]), type = "drift", 
                                    lags = 1))
without_corona <- list(
  e_lpd2, cr2, my2, fr2, ms2, gdp2, d_e_lpd2, d_cr2, d_my2, d_fr2, d_ms2, d_gdp2
)

result_table <- data.frame(
  without_corona = sapply(without_corona, function(x){x@teststat[1]}), 
  with_corona = sapply(with_corona, function(x){x@teststat[1]})
)
stars <- rev(c("*", "**", "***"))
result_table <- round(result_table, 4)
result_table[, 1] <- sapply(1:12, function(i){paste(
    result_table[i, 1], 
    ifelse(
        is.na(stars[result_table[i, 1] < without_corona[[i]]@cval[1, ]][1]),
        "", stars[result_table[i, 1] < without_corona[[i]]@cval[1, ]][1]
    )
)})
result_table[, 2] <- sapply(1:12, function(i){paste(
    result_table[i, 2], 
    ifelse(
        is.na(stars[result_table[i, 2] < with_corona[[i]]@cval[1, ]][1]),
        "", stars[result_table[i, 2] < with_corona[[i]]@cval[1, ]][1]
    )
)})

rownames(result_table) <- c(
  "$\\tilde{\\eta}_t$", "$cr_t$", "$my_t$", "$fr_t$", "$ms_t$", "$gdp_t$",
  "$\\Delta\\tilde{\\eta}_t$", "$\\Delta cr_t$", "$\\Delta my_t$", 
  "$\\Delta fr_t$", "$\\Delta ms_t$",  "$\\Delta gdp_t$"
)
opts <- options(knitr.kable.NA = "")
knitr::kable(
  result_table, 
  row.names = TRUE,
  col.names = c("31/12/1970 - 31/12/2019", "31/12/1970 - 30/09/2020"),
  caption = "Cointegration analysis: Augmented Dickey-Fuller test excluding and including the year 2020", 
  booktabs = TRUE, escape = FALSE,
  linesep = "\\addlinespace", 
  align = rep("c", 2)
) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::kable_styling(latex_options = "hold_position") %>%
  kableExtra::add_header_above(c(" ", "ADF-Test" = 2)) %>%
  kableExtra::footnote(
    symbol = c("Significance at 1% level", 
               "Significance at 5% level",
               "Significance at 10% level"),
    symbol_manual = rev(c("*", "**", "***")),
    footnote_as_chunk = T
  )
```

For variables in level the test is applied with a constant and drift and for variables in difference only a constant term has been added. Moreover, for all factors, except consumption risk, the significance results indicate first order integration at conventional significance levels. Furthermore, the test results for consumption risk hint at stationarity  for the case of the whole time series and at a integrated process for the time series without the year 2000. As in [@h2_paper] the middle aged to young ratio will be handled as a first order integrated time series.

```{r, cointegration-analysis-study, eval=TRUE, echo=FALSE}
traj <- rbind(
  result[[1]]@filter.traj[1, 5000:20000, ], 
  result[[2]]@filter.traj[1, 5000:20000, ],
  result[[3]]@filter.traj[1, 5000:20000, ]
)

data <- data.frame(
  e_lpd = colMeans(traj)[-1], cr = y$cr, mys = y$mys, fr = y$fr, ms = y$ms, 
  gdp = y$gdp
)

# with corona
ardl_model_1 <- ARDL::ardl(
  e_lpd ~ cr + mys + fr + ms + gdp, order = c(3, 1, 1, 1, 1, 1), data = data
)
cointegration_model_1 <- ARDL::uecm(ardl_model_1)
cointegration_model_1 <- summary(cointegration_model_1)

m_1 <- lm(e_lpd ~ -1 + cr + mys + fr + ms + gdp, data = data)
m_1 <- summary(m_1)

# without corona
ardl_model_2 <- ARDL::ardl(
  e_lpd ~ cr + mys + fr + ms + gdp, order = c(3, 1, 1, 1, 1, 1), 
  data = data[1:197, ]
)
cointegration_model_2 <- ARDL::uecm(ardl_model_2)
cointegration_model_2 <- summary(cointegration_model_2)

m_2 <- lm(e_lpd ~ -1 + cr + mys + fr + ms + gdp, data = data[1:197, ])
m_2 <- summary(m_2)

result_table <- data.frame(
  without_corona = c(
    cointegration_model_2$coefficients[2, 1], m_2$coefficients[, 1],
    cointegration_model_2$r.squared, cointegration_model_2$adj.r.squared
  ),
  with_corona = c(
    cointegration_model_1$coefficients[2, 1], m_1$coefficients[, 1], 
    cointegration_model_1$r.squared, cointegration_model_1$adj.r.squared
  )
)
result_table <- round(result_table, 4)
result_table[, 1] <- sapply(1:12, function(i){paste(
    result_table[i, 1], 
    ifelse(
        ,
        "", stars[result_table[i, 1] < without_corona[[i]]@cval[1, ]][1]
    )
)})
result_table[, 2] <- sapply(1:12, function(i){paste(
    result_table[i, 2], 
    ifelse(
        is.na(stars[result_table[i, 2] < with_corona[[i]]@cval[1, ]][1]),
        "", stars[result_table[i, 2] < with_corona[[i]]@cval[1, ]][1]
    )
)})
rownames(result_table) <- c(
  "$\\alpha$", "$\\beta_1$", "$\\beta_2$", "$\\beta_3$",
  "$\\beta_4$", "$\\beta_5$", "$R^2$", "adj $R^2$"
)
opts <- options(knitr.kable.NA = "")
knitr::kable(
  result_table, 
  row.names = TRUE,
  col.names = c("31/12/1970 - 31/12/2019", "31/12/1970 - 30/09/2020"),
  caption = "Cointegration analysis: Results", 
  booktabs = TRUE, escape = FALSE,
  linesep = "\\addlinespace", 
  align = rep("c", 2)
) %>% 
  kableExtra::kable_paper() %>%
  kableExtra::kable_styling(latex_options = "hold_position") %>%
  kableExtra::footnote(
    symbol = c("Significance at 1% level", 
               "Significance at 5% level",
               "Significance at 10% level"),
    symbol_manual = rev(c("*", "**", "***")),
    footnote_as_chunk = T
  )
```
\newpage

## State process extension with covariates

## Model comparison
